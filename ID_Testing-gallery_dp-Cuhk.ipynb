{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c590ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "from importlib import import_module\n",
    "from itertools import count\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "import tensorflow as tf\n",
    "\n",
    "import commoncuhk\n",
    "import loss\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import LeakyReLU, Concatenate, concatenate, Lambda, UpSampling2D, Add, Input, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea04531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    excluder= 'market1501' #, 'diagonal','cuhk03','duke'\n",
    "    query_dataset = '/home/k/kajal/triplet-reid/data/cuhk03-np/detected_query.csv'\n",
    "    query_embeddings = '/home/k/kajal/triplet-reid/experiments/cuhk_pepnet/query_embeddings.h5'\n",
    "    query_embeddings_adv = '/home/k/kajal/triplet-reid/experiments/cuhk1rec/query_embeddings.h5'\n",
    "    gallery_dataset = '/home/k/kajal/triplet-reid/data/cuhk03-np/detected_test.csv'\n",
    "    gallery_embeddings =  '/home/k/kajal/triplet-reid/experiments/cuhk_pepnet/gallery_embeddings.h5'\n",
    "    metric =  'euclidean'\n",
    "    #filename = \n",
    "    batch_size = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f340f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc995128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the query and gallery data from the CSV files.\n",
    "query_pids, query_fids = commoncuhk.load_dataset(args.query_dataset, None)\n",
    "gallery_pids, gallery_fids = commoncuhk.load_dataset(args.gallery_dataset, None)\n",
    "\n",
    "# Load the two datasets fully into memory.\n",
    "with h5py.File(args.query_embeddings, 'r') as f_query:\n",
    "    query_embs = np.array(f_query['emb'])\n",
    "    query_embs_dp = np.array(f_query['emb'])\n",
    "\n",
    "\n",
    "with h5py.File(args.gallery_embeddings, 'r') as f_gallery:\n",
    "    gallery_embs = np.array(f_gallery['emb'])\n",
    "    gallery_embs_dp = np.array(f_gallery['emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d241b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_embs=gallery_embs\n",
    "gallery_embs_dp=gallery_embs_dp\n",
    "gallery_pids=gallery_pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1191a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_pids=np.unique(gallery_pids)\n",
    "print(len(uni_pids))\n",
    "uni_query_pids=np.unique(query_pids)\n",
    "len(uni_query_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e17ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 128)\n",
      "(5332, 128)\n"
     ]
    }
   ],
   "source": [
    "print(query_embs.shape)\n",
    "print(gallery_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875f7e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.2034714  -1.2927732   0.87319475  0.708815    3.128399    0.10258525\n",
      "  0.5819795  -5.3290186  -0.00696615 -0.65817046  4.1388006  -0.1405488\n",
      "  3.6700864  -5.9736433  -0.18021151 -1.9956342   5.06066     0.5869995\n",
      "  2.2143734  -1.500974    1.9035482  -1.7543072  -0.6153123   2.0689025\n",
      " -2.5458465  -1.4771395  -0.44672918  2.3772175  -1.2336417  -0.10243905\n",
      " -4.1896257   3.1497483  -1.0488262   2.6556268   1.0072933   1.9376538\n",
      "  0.635422   -4.052031    0.27907348  2.953896   -0.54858744  2.072812\n",
      " -3.903998   -1.0724238   1.0174351   0.34009045  0.7049166  -0.516996\n",
      "  0.49609482 -4.4458303   0.44458765  1.0506483  -0.6284567   2.8564775\n",
      "  1.3777007  -0.8946021   2.0027823  -1.362541    0.320893    1.0560054\n",
      "  0.94164836 -4.468156    2.9926534   1.387099    1.973374    5.056146\n",
      "  0.5344552  -1.3215115  -3.3295658  -0.18862541  0.50694364 -0.12669206\n",
      " -0.24016316  4.1486664   0.35141796 -1.4002954  -1.8437268   0.05918837\n",
      " -1.4106699   0.51893854  1.6829897   3.209666    0.75877595  2.9059367\n",
      " -0.2753149  -2.6618853  -0.18188587 -3.485406   -1.3746248  -0.36646044\n",
      " -4.3372684   0.43699837 -2.2597969   2.8581388   2.474012    1.3104494\n",
      " -2.0082133  -2.295172   -0.01895247 -1.2758117  -1.0470256   1.8009329\n",
      "  1.5492843  -0.22451147  6.724108   -2.2553048  -2.4949238   2.5582392\n",
      " -1.7018136   3.546645   -1.9825568   2.4926486   3.2163193  -0.41218472\n",
      "  1.202623   -0.27521765  1.5775996   1.1928152   0.94312185 -1.1007757\n",
      "  1.3489776   1.0786245  -2.9040918   4.3373375   1.0766987   3.0864346\n",
      "  0.7069442  -1.6626314 ] [ 1.15484393e+00  1.63401353e+00  2.47940755e+00 -2.41979504e+00\n",
      " -1.33807921e+00  1.91804457e+00  2.52408695e+00 -1.12088874e-01\n",
      "  7.07429230e-01 -2.61709738e+00  1.40202379e+00 -2.71405935e+00\n",
      "  8.59850407e-01 -6.10424429e-02 -9.89503026e-01 -2.64636374e+00\n",
      "  1.01795232e+00 -5.92813790e-01  1.56808591e+00 -1.45730436e+00\n",
      " -3.24914646e+00 -5.74545383e-01 -7.09025979e-01  3.77983540e-01\n",
      " -1.23637915e+00 -2.27454901e+00  5.86929321e-01 -1.62651360e+00\n",
      " -1.15644312e+00 -2.35359311e+00  7.15898350e-02 -1.61262739e+00\n",
      " -2.20182657e+00 -1.54694939e+00 -2.37224817e-01 -9.14521337e-01\n",
      "  1.11598229e+00  1.45441020e+00  4.45666075e-01 -1.99930155e+00\n",
      " -1.37590694e+00 -9.31718349e-01 -1.15176773e+00  2.48012471e+00\n",
      "  4.59039658e-01  1.04172611e+00  1.24795532e+00  3.42533994e+00\n",
      "  5.74243888e-02 -4.60618675e-01 -1.21568406e+00 -1.34018743e+00\n",
      "  1.56822443e+00  1.23798931e+00  4.61322832e+00  1.75964117e+00\n",
      "  1.80845118e+00 -8.43750715e-01 -1.09990704e+00  1.01907945e+00\n",
      " -1.38022804e+00 -1.04327750e+00  7.51006424e-01 -4.24983215e+00\n",
      "  1.29931247e+00  9.29116726e-01 -1.27022278e+00  1.10414863e+00\n",
      " -1.42916453e+00 -5.23586750e-01 -3.22215199e-01 -1.46119058e+00\n",
      " -1.79708743e+00  2.44384789e+00 -4.44159806e-01 -2.16292715e+00\n",
      "  7.26955652e-01 -2.85161161e+00  9.00506556e-01 -9.23121512e-01\n",
      "  1.07880270e+00 -1.41269946e+00  9.39332366e-01 -2.50876665e-01\n",
      "  3.04179025e+00  3.16268635e+00  4.29056019e-01  4.82421517e-01\n",
      " -5.50143242e-01 -1.24977641e-01  3.97606015e-01  2.43096256e+00\n",
      "  8.67720246e-02  1.73251414e+00 -1.46606505e+00  4.43692356e-01\n",
      " -9.78110373e-01 -4.31542516e-01  1.69914216e-01 -3.44400597e+00\n",
      " -1.50007278e-01 -1.11225247e+00  3.66337091e-01  8.63859057e-01\n",
      "  1.72845697e+00 -9.43435550e-01  4.91549015e+00  8.94251347e-01\n",
      "  1.66797984e+00 -1.44355345e+00  2.24023151e+00 -1.30966294e+00\n",
      "  3.25189734e+00 -2.87477642e-01  1.52585804e+00 -6.91504240e-01\n",
      " -3.75489664e+00 -1.24133006e-03  5.89992821e-01  5.42810678e-01\n",
      "  5.34982502e-01  2.45787024e+00  5.07711709e-01 -8.35993111e-01\n",
      " -8.74411702e-01  3.50693017e-01  9.49752569e-01  8.59188259e-01]\n"
     ]
    }
   ],
   "source": [
    "print(query_embs[0],query_embs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d48cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.129788 -0.03733886 8.56692 1.9269185\n",
      "-9.302376 -0.03968162 8.700699 1.9250435\n"
     ]
    }
   ],
   "source": [
    "#query_embs_dp=query_embs\n",
    "query_embs_dp.shape\n",
    "query_embs[0]\n",
    "print(np.min(query_embs),np.mean(query_embs),np.max(query_embs),np.std(query_embs))\n",
    "print(np.min(gallery_embs),np.mean(gallery_embs),np.max(gallery_embs),np.std(gallery_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7288d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embs_dp[0,1]=np.random.normal(0,1.9269185)\n",
    "query_embs_dp=np.exp(0.1) * query_embs_dp +0.001\n",
    "gallery_embs_dp[0,1]=np.random.normal(0,1.9269185)\n",
    "gallery_embs_dp=np.exp(0.1) * gallery_embs_dp +0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe3c43a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.701109 18.082117\n"
     ]
    }
   ],
   "source": [
    "def l1(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.max(np.subtract(actual,pred)).mean()\n",
    "\n",
    "def mse(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.max(np.square(np.subtract(actual,pred)).mean())\n",
    "\n",
    "D0 = query_embs + np.random.normal(0,1.9269185)\n",
    "D1 = query_embs_dp + np.random.normal(0,1.9269185)\n",
    "\n",
    "D2 = gallery_embs + np.random.normal(0,1.9269185)\n",
    "D3 = gallery_embs_dp + np.random.normal(0,1.9269185)\n",
    "#print(D0,D1)\n",
    "#sens1 = l1(query_embs,query_embs_dp)\n",
    "sensq = mse(D0,D1)\n",
    "sensg = mse(D2,D3)\n",
    "print(sensq,sensg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e8f38c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values ['722' '103' '156' ... '369' '374' '1107']\n",
      "encoded [538  18 234 ... 351 354  53]\n",
      "(1400, 700)\n"
     ]
    }
   ],
   "source": [
    "query_data = query_pids\n",
    "query_values = array(query_data)\n",
    "print('values', query_values)\n",
    "# integer encode\n",
    "query_label_encoder = LabelEncoder()\n",
    "query_integer_encoded = query_label_encoder.fit_transform(query_values)\n",
    "print('encoded', query_integer_encoded)\n",
    "# binary encode\n",
    "query_onehot_encoder = OneHotEncoder(sparse=False)\n",
    "query_integer_encoded = query_integer_encoded.reshape(len(query_integer_encoded), 1)\n",
    "query_onehot_encoded = query_onehot_encoder.fit_transform(query_integer_encoded)\n",
    "print(query_onehot_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5e8f744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values ['136' '704' '303' ... '1111' '802' '1199']\n",
      "encoded [177 527 314 ...  56 586 101]\n",
      "(5332, 700)\n"
     ]
    }
   ],
   "source": [
    "data = gallery_pids\n",
    "values = array(data)\n",
    "print('values', values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print('encoded', integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5569cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = D3\n",
    "Y_train_label = onehot_encoded\n",
    "X_test = D0\n",
    "Y_test_label = query_onehot_encoded\n",
    "#print(X_train.size)\n",
    "#print(X_test.size)\n",
    "#print(Y_train_label)\n",
    "#print(Y_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27ad0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Y_train_label[2:5000])\n",
    "#y_train_label = to_categorical(Y_train_label)\n",
    "#y_train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6c5e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 700)               90300     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,300\n",
      "Trainable params: 90,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "#model.add( Dense(units=512, input_dim=128, kernel_initializer='normal', activation='relu') )\n",
    "#model.add( Dropout(0.5))\n",
    "model.add( Dense(units=700, input_dim=128, kernel_initializer='normal', activation='softmax') )\n",
    "print( model.summary() )\n",
    "model.compile( loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fe9922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "34/34 - 3s - loss: 6.4131 - accuracy: 0.0265 - val_loss: 5.7672 - val_accuracy: 0.0366 - 3s/epoch - 100ms/step\n",
      "Epoch 2/6\n",
      "34/34 - 1s - loss: 4.3512 - accuracy: 0.2326 - val_loss: 4.6371 - val_accuracy: 0.1612 - 522ms/epoch - 15ms/step\n",
      "Epoch 3/6\n",
      "34/34 - 0s - loss: 3.0645 - accuracy: 0.5329 - val_loss: 3.8162 - val_accuracy: 0.2952 - 342ms/epoch - 10ms/step\n",
      "Epoch 4/6\n",
      "34/34 - 0s - loss: 2.2169 - accuracy: 0.7503 - val_loss: 3.2424 - val_accuracy: 0.3861 - 285ms/epoch - 8ms/step\n",
      "Epoch 5/6\n",
      "34/34 - 0s - loss: 1.6468 - accuracy: 0.8530 - val_loss: 2.8111 - val_accuracy: 0.4789 - 300ms/epoch - 9ms/step\n",
      "Epoch 6/6\n",
      "34/34 - 0s - loss: 1.2675 - accuracy: 0.9069 - val_loss: 2.5051 - val_accuracy: 0.5351 - 322ms/epoch - 9ms/step\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x=X_train, y=Y_train_label, validation_split=0.2, epochs=6, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89cc86fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "44/44 [==============================] - 0s 5ms/step - loss: 2.5581 - accuracy: 0.4114\n",
      "test loss, test acc: [2.5580813884735107, 0.4114285707473755]\n",
      "Generate predictions for 3 samples\n",
      "44/44 [==============================] - 0s 4ms/step\n",
      "predictions shape: [[2.20238324e-03 5.06063807e-04 1.63405514e-06 ... 2.70761757e-05\n",
      "  1.35950741e-05 3.45673106e-05]\n",
      " [3.58659927e-05 9.97593510e-04 1.00829020e-05 ... 1.49146272e-05\n",
      "  8.03363582e-05 3.83569393e-04]\n",
      " [1.38842268e-04 5.05935343e-04 4.05818264e-06 ... 1.54798181e-04\n",
      "  1.05616709e-05 5.79839179e-05]\n",
      " ...\n",
      " [7.27685574e-06 7.42731027e-06 1.91160848e-06 ... 7.87551107e-05\n",
      "  1.62542819e-05 8.70798540e-05]\n",
      " [5.82680186e-05 1.98728614e-03 2.20124434e-06 ... 1.13364724e-04\n",
      "  6.79065415e-05 2.55317300e-05]\n",
      " [1.50195331e-06 2.15825230e-01 1.42132951e-04 ... 2.72897450e-04\n",
      "  1.02202685e-05 5.93600911e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, Y_test_label)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(X_test)\n",
    "print(\"predictions shape:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a71f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffprivlib.models import GaussianNB\n",
    "clf = GaussianNB(epsilon=1,bounds=(-50e50, 50e50))\n",
    "clf.fit(X_train, gallery_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a95318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)\n",
    "print(\"Test accuracy: %f\" % clf.score(X_test, query_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cec2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hbeta(D=np.array([]), beta=1.0):\n",
    "    \"\"\"\n",
    "        Compute the perplexity and the P-row for a specific value of the\n",
    "        precision of a Gaussian distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute P-row and corresponding perplexity\n",
    "    P = np.exp(-D.copy() * beta)\n",
    "    sumP = sum(P)\n",
    "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "    P = P / sumP\n",
    "    return H, P\n",
    "\n",
    "def x2p(X=np.array([]), tol=1e-5, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Performs a binary search to get P-values in such a way that each\n",
    "        conditional Gaussian has the same perplexity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize some variables\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    (n, d) = X.shape\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    P = np.zeros((n, n))\n",
    "    beta = np.ones((n, 1))\n",
    "    logU = np.log(perplexity)\n",
    "\n",
    "    # Loop over all datapoints\n",
    "    for i in range(n):\n",
    "\n",
    "        # Print progress\n",
    "        if i % 500 == 0:\n",
    "            print(\"Computing P-values for point %d of %d...\" % (i, n))\n",
    "\n",
    "        # Compute the Gaussian kernel and entropy for the current precision\n",
    "        betamin = -np.inf\n",
    "        betamax = np.inf\n",
    "        Di = D[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))]\n",
    "        (H, thisP) = Hbeta(Di, beta[i])\n",
    "\n",
    "        # Evaluate whether the perplexity is within tolerance\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while np.abs(Hdiff) > tol and tries < 50:\n",
    "\n",
    "            # If not, increase or decrease precision\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i].copy()\n",
    "                if betamax == np.inf or betamax == -np.inf:\n",
    "                    beta[i] = beta[i] * 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2.\n",
    "            else:\n",
    "                betamax = beta[i].copy()\n",
    "                if betamin == np.inf or betamin == -np.inf:\n",
    "                    beta[i] = beta[i] / 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2.\n",
    "\n",
    "            # Recompute the values\n",
    "            (H, thisP) = Hbeta(Di, beta[i])\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "\n",
    "        # Set the final row of P\n",
    "        P[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))] = thisP\n",
    "\n",
    "    # Return final P-matrix\n",
    "    print(\"Mean value of sigma: %f\" % np.mean(np.sqrt(1 / beta)))\n",
    "    return P\n",
    "\n",
    "def pca(X=np.array([]), no_dims=50):\n",
    "    \"\"\"\n",
    "        Runs PCA on the NxD array X in order to reduce its dimensionality to\n",
    "        no_dims dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Preprocessing the data using PCA...\")\n",
    "    (n, d) = X.shape\n",
    "    X = X - np.tile(np.mean(X, 0), (n, 1))\n",
    "    (l, M) = np.linalg.eig(np.dot(X.T, X))\n",
    "    Y = np.dot(X, M[:, 0:no_dims])\n",
    "    return Y\n",
    "def tsne(X=np.array([]), no_dims=2, initial_dims=50, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    # Initialize variables\n",
    "    X = pca(X, initial_dims).real\n",
    "    (n, d) = X.shape\n",
    "    max_iter = 10\n",
    "    initial_momentum = 0.5\n",
    "    final_momentum = 0.8\n",
    "    eta = 200\n",
    "    min_gain = 0.01\n",
    "    Y = np.random.randn(n, no_dims)\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Compute P-values\n",
    "    P = x2p(X, 1e-5, perplexity)\n",
    "    P = P + np.transpose(P)\n",
    "    P = P / np.sum(P)\n",
    "    P = P * 4.\t\t\t\t\t\t\t\t\t# early exaggeration\n",
    "    P = np.maximum(P, 1e-12)\n",
    "    \n",
    "\n",
    "    # Run iterations\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        # Compute pairwise affinities\n",
    "        sum_Y = np.sum(np.square(Y), 1)\n",
    "        num = -2. * np.dot(Y, Y.T)\n",
    "        num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "        num[range(n), range(n)] = 0.\n",
    "        Q = num / np.sum(num)\n",
    "        Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "        # Compute gradient\n",
    "        PQ = P - Q\n",
    "        for i in range(n):\n",
    "            dY[i, :] = np.sum(np.tile(PQ[:, i] * num[:, i], (no_dims, 1)).T * (Y[i, :] - Y), 0)\n",
    "\n",
    "        # Perform the update\n",
    "        if iter < 20:\n",
    "            momentum = initial_momentum\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)) + \\\n",
    "                (gains * 0.8) * ((dY > 0.) == (iY > 0.))\n",
    "        gains[gains < min_gain] = min_gain\n",
    "        iY = momentum * iY - eta * (gains * dY)\n",
    "        Y = Y + iY\n",
    "        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
    "\n",
    "        # Compute current value of cost function\n",
    "        if (iter + 1) % 10 == 0:\n",
    "            C = np.sum(P * np.log(P / Q))\n",
    "            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n",
    "\n",
    "        # Stop lying about P-values\n",
    "        if iter == 100:\n",
    "            P = P / 4.\n",
    "\n",
    "    # Return solution\n",
    "    return Y\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb470a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "X = gallery_embs[500:700]\n",
    "lbl=list(map(int,gallery_pids))\n",
    "labels = lbl[500:700]#query_pids[0:20]\n",
    "pylab.figure()\n",
    "Y = tsne(X, 2, 50, 20.0)\n",
    "plt=pylab.scatter(Y[:, 0],Y[:,1],10,labels,marker='o')\n",
    "pylab.axis('off')\n",
    "pylab.savefig('rsltn3n1.pdf')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, Y_test_label)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(X_test)\n",
    "print(\"predictions shape:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed85944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "X = query_embs[500:700]\n",
    "lbl=list(map(int,query_pids))\n",
    "labels = lbl[500:700]#query_pids[0:20]\n",
    "pylab.figure()\n",
    "Y = tsne(X, 2, 50, 20.0)\n",
    "plt=pylab.scatter(Y[:, 0],Y[:,1],10,labels,marker='o')\n",
    "pylab.axis('off')\n",
    "pylab.savefig('rsltn3n2.pdf')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #file = query_embs\n",
    "    #filel = query_pids\n",
    "    X = query_embs[0:50]\n",
    "    lbl=list(map(int,query_pids))\n",
    "    labels = lbl[0:50]#query_pids[0:20]\n",
    "    print(query_embs,query_pids)\n",
    "    #X = np.loadtxt(\"mnist2500_X.txt\")\n",
    "    pylab.figure()\n",
    "    Y = tsne(X, 2, 50, 20.0)\n",
    "    plt=pylab.scatter(Y[:, 0],Y[:,1],30,labels,marker='+')\n",
    "    pylab.axis('off')\n",
    "    pylab.legend('on')\n",
    "    pylab.savefig('rsltn3n1.pdf')\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #file = query_embs\n",
    "    #filel = query_pids\n",
    "    X = query_embs[0:50]\n",
    "    lbl=list(map(int,query_pids))\n",
    "    labels = lbl[0:50]#query_pids[0:20]\n",
    "    print(query_embs,query_pids)\n",
    "    #X = np.loadtxt(\"mnist2500_X.txt\")\n",
    "    pylab.figure()\n",
    "    Y = tsne(X, 2, 50, 20.0)\n",
    "    plt=pylab.scatter(Y[:, 0],Y[:,1],30,labels,marker='+')\n",
    "    pylab.axis('off')\n",
    "    pylab.legend('on')\n",
    "    pylab.savefig('rsltn3n1.pdf')\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb94d74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
