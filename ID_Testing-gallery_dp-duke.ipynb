{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c590ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "from importlib import import_module\n",
    "from itertools import count\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "import tensorflow as tf\n",
    "\n",
    "import common\n",
    "import loss\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import LeakyReLU, Concatenate, concatenate, Lambda, UpSampling2D, Add, Input, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52af0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=3 python evaluate.py-tr --excluder duke \n",
    "--query_dataset ~/triplet-reid/data/duke/dukeMTMC_query.csv \n",
    "--query_embeddings ~/triplet-reid/experiments/duke_gauss/aug_query_embeddin.gs.h5 \n",
    "--gallery_dataset ~/triplet-reid/data/duke/dukeMTMC_test.csv \n",
    "--gallery_embeddings ~/triplet-reid/experiments/duke_gauss/aug_gallery_embeddings.h5 e--metric euclidean --batch_size 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b441c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    excluder= 'duke' #, 'diagonal','cuhk03','duke'\n",
    "    query_dataset = '/home/k/kajal/triplet-reid/data/duke/dukeMTMC_query.csv'\n",
    "    query_embeddings = '/home/k/kajal/triplet-reid/experiments/duke_pixel_ce_exp/aug_query_embeddings.h5'\n",
    "    #query_embeddings_adv = '/home/k/kajal/triplet-reid/experiments//MARKET/marketrecon255/test_embeddings.h5'\n",
    "    gallery_dataset = '/home/k/kajal/triplet-reid/data/duke/dukeMTMC_test.csv'\n",
    "    gallery_embeddings =  '/home/k/kajal/triplet-reid/experiments/duke_pixel_ce_exp/aug_gallery_embeddings.h5'\n",
    "    metric =  'euclidean'\n",
    "    #filename = \n",
    "    batch_size = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f340f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc995128",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = '/home/k/kajal/triplet-reid/experiments/duke_pixel_ce_exp/aug_query_embeddings.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1e8147ebde26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the two datasets fully into memory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_query\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mquery_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_query\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mquery_embs_dp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_query\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                                swmr=swmr)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = '/home/k/kajal/triplet-reid/experiments/duke_pixel_ce_exp/aug_query_embeddings.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# Load the query and gallery data from the CSV files.\n",
    "query_pids, query_fids = common.load_dataset(args.query_dataset, None)\n",
    "gallery_pids, gallery_fids = common.load_dataset(args.gallery_dataset, None)\n",
    "\n",
    "# Load the two datasets fully into memory.\n",
    "with h5py.File(args.query_embeddings, 'r') as f_query:\n",
    "    query_embs = np.array(f_query['emb'])\n",
    "    query_embs_dp = np.array(f_query['emb'])\n",
    "with h5py.File(args.gallery_embeddings, 'r') as f_gallery:\n",
    "    gallery_embs = np.array(f_gallery['emb'])\n",
    "    gallery_embs_dp = np.array(f_gallery['emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d241b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_embs=gallery_embs[6618:]\n",
    "gallery_embs_dp=gallery_embs_dp[6618:]\n",
    "gallery_pids=gallery_pids[6618:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1191a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_pids=np.unique(gallery_pids)\n",
    "print(len(uni_pids))\n",
    "uni_query_pids=np.unique(query_pids)\n",
    "len(uni_query_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e17ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_embs.shape)\n",
    "print(gallery_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_embs[0],query_embs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d48cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_embs_dp=query_embs\n",
    "query_embs_dp.shape\n",
    "query_embs[0]\n",
    "print(np.min(query_embs),np.mean(query_embs),np.max(query_embs),np.std(query_embs))\n",
    "print(np.min(gallery_embs),np.mean(gallery_embs),np.max(gallery_embs),np.std(gallery_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7288d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embs_dp[0,1]=np.random.normal(0,2.312213)\n",
    "query_embs_dp=np.exp(0.5) * query_embs_dp +0.01\n",
    "gallery_embs_dp[0,1]=np.random.normal(0,2.3505316)\n",
    "gallery_embs_dp=np.exp(0.5) * gallery_embs_dp +0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c43a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.max(np.subtract(actual,pred)).mean()\n",
    "\n",
    "def mse(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.max(np.square(np.subtract(actual,pred)).mean())\n",
    "\n",
    "D0 = query_embs + np.random.normal(0,1.3787516)\n",
    "D1 = query_embs_dp + np.random.normal(0,1.3787516)\n",
    "\n",
    "D2 = gallery_embs + np.random.normal(0,1.3921114)\n",
    "D3 = gallery_embs_dp + np.random.normal(0,1.3921114)\n",
    "#print(D0,D1)\n",
    "#sens1 = l1(query_embs,query_embs_dp)\n",
    "sensq = mse(D0,D1)\n",
    "sensg = mse(D2,D3)\n",
    "print(sensq,sensg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_data = query_pids\n",
    "query_values = array(query_data)\n",
    "print('values', query_values)\n",
    "# integer encode\n",
    "query_label_encoder = LabelEncoder()\n",
    "query_integer_encoded = query_label_encoder.fit_transform(query_values)\n",
    "print('encoded', query_integer_encoded)\n",
    "# binary encode\n",
    "query_onehot_encoder = OneHotEncoder(sparse=False)\n",
    "query_integer_encoded = query_integer_encoded.reshape(len(query_integer_encoded), 1)\n",
    "query_onehot_encoded = query_onehot_encoder.fit_transform(query_integer_encoded)\n",
    "print(query_onehot_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e8f744",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gallery_pids\n",
    "values = array(data)\n",
    "print('values', values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print('encoded', integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = D3\n",
    "Y_train_label = onehot_encoded\n",
    "X_test = D0\n",
    "Y_test_label = query_onehot_encoded\n",
    "#print(X_train.size)\n",
    "#print(X_test.size)\n",
    "#print(Y_train_label)\n",
    "#print(Y_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Y_train_label[2:5000])\n",
    "#y_train_label = to_categorical(Y_train_label)\n",
    "#y_train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5e22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "#model.add( Dense(units=512, input_dim=128, kernel_initializer='normal', activation='relu') )\n",
    "#model.add( Dropout(0.5))\n",
    "model.add( Dense(units=750, input_dim=128, kernel_initializer='normal', activation='softmax') )\n",
    "print( model.summary() )\n",
    "model.compile( loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe9922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = model.fit(x=X_train, y=Y_train_label, validation_split=0.2, epochs=1, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, Y_test_label)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(X_test)\n",
    "print(\"predictions shape:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a71f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffprivlib.models import GaussianNB\n",
    "clf = GaussianNB(epsilon=1,bounds=(-50e50, 50e50))\n",
    "clf.fit(X_train, gallery_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a95318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)\n",
    "print(\"Test accuracy: %f\" % clf.score(X_test, query_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cec2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hbeta(D=np.array([]), beta=1.0):\n",
    "    \"\"\"\n",
    "        Compute the perplexity and the P-row for a specific value of the\n",
    "        precision of a Gaussian distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute P-row and corresponding perplexity\n",
    "    P = np.exp(-D.copy() * beta)\n",
    "    sumP = sum(P)\n",
    "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "    P = P / sumP\n",
    "    return H, P\n",
    "\n",
    "def x2p(X=np.array([]), tol=1e-5, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Performs a binary search to get P-values in such a way that each\n",
    "        conditional Gaussian has the same perplexity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize some variables\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    (n, d) = X.shape\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    P = np.zeros((n, n))\n",
    "    beta = np.ones((n, 1))\n",
    "    logU = np.log(perplexity)\n",
    "\n",
    "    # Loop over all datapoints\n",
    "    for i in range(n):\n",
    "\n",
    "        # Print progress\n",
    "        if i % 500 == 0:\n",
    "            print(\"Computing P-values for point %d of %d...\" % (i, n))\n",
    "\n",
    "        # Compute the Gaussian kernel and entropy for the current precision\n",
    "        betamin = -np.inf\n",
    "        betamax = np.inf\n",
    "        Di = D[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))]\n",
    "        (H, thisP) = Hbeta(Di, beta[i])\n",
    "\n",
    "        # Evaluate whether the perplexity is within tolerance\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while np.abs(Hdiff) > tol and tries < 50:\n",
    "\n",
    "            # If not, increase or decrease precision\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i].copy()\n",
    "                if betamax == np.inf or betamax == -np.inf:\n",
    "                    beta[i] = beta[i] * 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2.\n",
    "            else:\n",
    "                betamax = beta[i].copy()\n",
    "                if betamin == np.inf or betamin == -np.inf:\n",
    "                    beta[i] = beta[i] / 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2.\n",
    "\n",
    "            # Recompute the values\n",
    "            (H, thisP) = Hbeta(Di, beta[i])\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "\n",
    "        # Set the final row of P\n",
    "        P[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))] = thisP\n",
    "\n",
    "    # Return final P-matrix\n",
    "    print(\"Mean value of sigma: %f\" % np.mean(np.sqrt(1 / beta)))\n",
    "    return P\n",
    "\n",
    "def pca(X=np.array([]), no_dims=50):\n",
    "    \"\"\"\n",
    "        Runs PCA on the NxD array X in order to reduce its dimensionality to\n",
    "        no_dims dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Preprocessing the data using PCA...\")\n",
    "    (n, d) = X.shape\n",
    "    X = X - np.tile(np.mean(X, 0), (n, 1))\n",
    "    (l, M) = np.linalg.eig(np.dot(X.T, X))\n",
    "    Y = np.dot(X, M[:, 0:no_dims])\n",
    "    return Y\n",
    "def tsne(X=np.array([]), no_dims=2, initial_dims=50, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    # Initialize variables\n",
    "    X = pca(X, initial_dims).real\n",
    "    (n, d) = X.shape\n",
    "    max_iter = 10\n",
    "    initial_momentum = 0.5\n",
    "    final_momentum = 0.8\n",
    "    eta = 200\n",
    "    min_gain = 0.01\n",
    "    Y = np.random.randn(n, no_dims)\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Compute P-values\n",
    "    P = x2p(X, 1e-5, perplexity)\n",
    "    P = P + np.transpose(P)\n",
    "    P = P / np.sum(P)\n",
    "    P = P * 4.\t\t\t\t\t\t\t\t\t# early exaggeration\n",
    "    P = np.maximum(P, 1e-12)\n",
    "    \n",
    "\n",
    "    # Run iterations\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        # Compute pairwise affinities\n",
    "        sum_Y = np.sum(np.square(Y), 1)\n",
    "        num = -2. * np.dot(Y, Y.T)\n",
    "        num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "        num[range(n), range(n)] = 0.\n",
    "        Q = num / np.sum(num)\n",
    "        Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "        # Compute gradient\n",
    "        PQ = P - Q\n",
    "        for i in range(n):\n",
    "            dY[i, :] = np.sum(np.tile(PQ[:, i] * num[:, i], (no_dims, 1)).T * (Y[i, :] - Y), 0)\n",
    "\n",
    "        # Perform the update\n",
    "        if iter < 20:\n",
    "            momentum = initial_momentum\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)) + \\\n",
    "                (gains * 0.8) * ((dY > 0.) == (iY > 0.))\n",
    "        gains[gains < min_gain] = min_gain\n",
    "        iY = momentum * iY - eta * (gains * dY)\n",
    "        Y = Y + iY\n",
    "        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
    "\n",
    "        # Compute current value of cost function\n",
    "        if (iter + 1) % 10 == 0:\n",
    "            C = np.sum(P * np.log(P / Q))\n",
    "            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n",
    "\n",
    "        # Stop lying about P-values\n",
    "        if iter == 100:\n",
    "            P = P / 4.\n",
    "\n",
    "    # Return solution\n",
    "    return Y\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb470a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "X = gallery_embs[500:700]\n",
    "lbl=list(map(int,gallery_pids))\n",
    "labels = lbl[500:700]#query_pids[0:20]\n",
    "pylab.figure()\n",
    "Y = tsne(X, 2, 50, 20.0)\n",
    "plt=pylab.scatter(Y[:, 0],Y[:,1],10,labels,marker='o')\n",
    "pylab.axis('off')\n",
    "pylab.savefig('rsltn3n1.pdf')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, Y_test_label)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(X_test)\n",
    "print(\"predictions shape:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed85944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "X = query_embs[500:700]\n",
    "lbl=list(map(int,query_pids))\n",
    "labels = lbl[500:700]#query_pids[0:20]\n",
    "pylab.figure()\n",
    "Y = tsne(X, 2, 50, 20.0)\n",
    "plt=pylab.scatter(Y[:, 0],Y[:,1],10,labels,marker='o')\n",
    "pylab.axis('off')\n",
    "pylab.savefig('rsltn3n2.pdf')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #file = query_embs\n",
    "    #filel = query_pids\n",
    "    X = query_embs[0:50]\n",
    "    lbl=list(map(int,query_pids))\n",
    "    labels = lbl[0:50]#query_pids[0:20]\n",
    "    print(query_embs,query_pids)\n",
    "    #X = np.loadtxt(\"mnist2500_X.txt\")\n",
    "    pylab.figure()\n",
    "    Y = tsne(X, 2, 50, 20.0)\n",
    "    plt=pylab.scatter(Y[:, 0],Y[:,1],30,labels,marker='+')\n",
    "    pylab.axis('off')\n",
    "    pylab.legend('on')\n",
    "    pylab.savefig('rsltn3n1.pdf')\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #file = query_embs\n",
    "    #filel = query_pids\n",
    "    X = query_embs[0:50]\n",
    "    lbl=list(map(int,query_pids))\n",
    "    labels = lbl[0:50]#query_pids[0:20]\n",
    "    print(query_embs,query_pids)\n",
    "    #X = np.loadtxt(\"mnist2500_X.txt\")\n",
    "    pylab.figure()\n",
    "    Y = tsne(X, 2, 50, 20.0)\n",
    "    plt=pylab.scatter(Y[:, 0],Y[:,1],30,labels,marker='+')\n",
    "    pylab.axis('off')\n",
    "    pylab.legend('on')\n",
    "    pylab.savefig('rsltn3n1.pdf')\n",
    "    pylab.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
