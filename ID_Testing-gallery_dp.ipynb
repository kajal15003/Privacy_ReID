{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c590ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "from importlib import import_module\n",
    "from itertools import count\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "import tensorflow as tf\n",
    "\n",
    "import common\n",
    "import loss\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import LeakyReLU, Concatenate, concatenate, Lambda, UpSampling2D, Add, Input, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04531b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b441c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    excluder= 'market1501' #, 'diagonal','cuhk03','duke'\n",
    "    query_dataset = '/home/k/kajal/triplet-reid/data/market1501/market1501_query.csv'\n",
    "    query_embeddings = '/home/k/kajal/triplet-reid/experiments/mkt_pixel_ce_exp/aug_query_embeddings.h5'\n",
    "    query_embeddings_adv = '/home/k/kajal/triplet-reid/experiments//MARKET/marketrecon255/test_embeddings.h5'\n",
    "    gallery_dataset = '/home/k/kajal/triplet-reid/data/market1501/market1501_test.csv'\n",
    "    gallery_embeddings =  '/home/k/kajal/triplet-reid/experiments/mkt_pixel_ce_exp/aug_gallery_embeddings.h5'\n",
    "    metric =  'euclidean'\n",
    "    #filename = \n",
    "    batch_size = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f340f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc995128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the query and gallery data from the CSV files.\n",
    "query_pids, query_fids = common.load_dataset(args.query_dataset, None)\n",
    "gallery_pids, gallery_fids = common.load_dataset(args.gallery_dataset, None)\n",
    "\n",
    "# Load the two datasets fully into memory.\n",
    "with h5py.File(args.query_embeddings, 'r') as f_query:\n",
    "    query_embs = np.array(f_query['emb'])\n",
    "    query_embs_dp = np.array(f_query['emb'])\n",
    "with h5py.File(args.gallery_embeddings, 'r') as f_gallery:\n",
    "    gallery_embs = np.array(f_gallery['emb'])\n",
    "    gallery_embs_dp = np.array(f_gallery['emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d241b012",
   "metadata": {},
   "outputs": [],
   "source": [
    "gallery_embs=gallery_embs[6618:]\n",
    "gallery_embs_dp=gallery_embs_dp[6618:]\n",
    "gallery_pids=gallery_pids[6618:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1191a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_pids=np.unique(gallery_pids)\n",
    "print(len(uni_pids))\n",
    "uni_query_pids=np.unique(query_pids)\n",
    "len(uni_query_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e17ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3368, 128)\n",
      "(13114, 128)\n"
     ]
    }
   ],
   "source": [
    "print(query_embs.shape)\n",
    "print(gallery_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875f7e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.4895324e+00  4.9818420e-01  7.6958352e-01 -7.2742596e-02\n",
      "  1.2921383e+00 -1.3292663e+00 -6.6451675e-01  2.2089496e-01\n",
      " -5.4692543e-01  9.0875167e-01 -2.6830935e+00  1.1928835e+00\n",
      " -7.6162750e-01 -1.6739820e+00 -2.6683328e+00 -9.6505082e-01\n",
      "  2.9969415e-01  2.4369028e+00 -2.5869861e+00  4.9287838e-01\n",
      "  1.5305965e+00 -1.2275312e+00  3.3783272e-01 -1.3281310e+00\n",
      "  5.2735442e-01 -3.5020718e-01  1.0744702e+00 -9.5970106e-01\n",
      "  5.7255012e-01 -1.3847376e+00  1.1607877e+00  1.7695973e+00\n",
      " -2.2717962e+00 -3.7673607e+00 -7.1160597e-01 -2.3803020e-01\n",
      "  2.5717223e+00  1.2124742e+00  2.3082561e+00  1.3672486e-03\n",
      " -6.6192621e-01 -2.7707446e-01 -1.0177685e+00  9.3757915e-01\n",
      "  1.1460953e+00 -5.2870208e-01  7.4943912e-01  1.5137751e-01\n",
      " -3.2341409e+00 -3.5842472e-01 -2.7776301e-01  6.1675835e-01\n",
      " -2.4815164e+00 -1.1225467e+00  2.1935356e+00  6.2268490e-01\n",
      "  4.0969354e-01  1.7986505e+00  7.7366823e-01 -2.4093692e-01\n",
      "  1.6228625e+00  1.6464910e-01 -2.2330117e-01  1.8286045e+00\n",
      "  3.3835578e+00  9.2288935e-01 -3.7064314e-01  1.6176865e+00\n",
      "  9.5214289e-01 -5.0008833e-01 -2.4302795e+00 -4.4930774e-01\n",
      " -1.7293291e+00 -1.0495909e-01  1.5725341e+00  1.8916485e+00\n",
      "  2.1174428e-01  8.3138621e-01 -1.3637092e+00 -2.6808674e+00\n",
      " -1.8598181e+00 -1.2878723e-01  3.4636292e+00  9.1358438e-02\n",
      " -9.0780169e-02  6.1530197e-01  2.6625413e-01  5.9229010e-01\n",
      "  3.8260418e-01  2.0871589e+00 -9.0616065e-01 -2.8091111e+00\n",
      " -1.0570322e+00 -4.6590775e-02 -1.0407543e+00 -1.9368343e+00\n",
      "  1.1293342e+00  1.2068362e+00 -1.1177841e+00  3.6699362e-02\n",
      "  2.7022345e+00 -1.5504969e-02 -2.8861281e-01  9.8548585e-01\n",
      " -1.5322204e-01  3.9975771e-01  2.4459748e-01 -9.7280407e-01\n",
      " -3.9544353e+00  2.2972333e+00  7.7523196e-01 -1.0414779e+00\n",
      " -3.3805475e-01 -4.6152243e-01 -1.9585578e-01  1.1378343e+00\n",
      " -1.3510393e+00  9.5099723e-01 -2.1194587e+00  5.9356219e-01\n",
      "  2.9150826e-01  1.7896172e+00  1.6959600e-01 -1.0405374e+00\n",
      " -2.2473433e+00  3.1511617e-01  2.1005921e+00  1.8878533e+00] [-0.8907331   0.24877541  0.45254236  0.957856    0.46586037 -1.526734\n",
      " -0.71884906  0.628476   -0.25563636  0.40557557 -3.0968258  -0.7421504\n",
      " -0.84099925 -0.56821656 -2.983916   -1.0698109  -1.0783738   2.2441006\n",
      " -2.5758224  -0.02800258 -0.6090816  -1.24374    -0.06210969 -3.1980412\n",
      " -0.14141513 -1.2962023  -0.30115038 -1.3804696   2.0319197  -3.1162832\n",
      "  1.1515267   0.62018216 -1.7631241  -2.2596092   0.2916935  -0.8680603\n",
      "  1.1286294   0.35509682  0.67386824  0.5716903  -0.80528605  0.91645145\n",
      "  0.44829997  0.73461735 -0.19336924 -0.34070104  1.2349442   1.0222552\n",
      " -3.035451   -0.7760445  -1.4354289  -0.3804965  -0.9867948  -1.6650932\n",
      "  0.92544043  1.6224558   0.7781273   2.2964644  -0.9302646  -1.2048402\n",
      "  1.4008783   0.2666096  -0.22168612  2.0009956   2.2758029   0.7900065\n",
      " -2.1220486  -0.7886017   0.48425403 -1.349447    0.29142135 -1.6948254\n",
      " -0.8247322   0.49460545  0.6451777   2.0442812  -1.014776    0.7099905\n",
      " -0.526244   -2.2621534  -1.9247887   0.4129567   0.62873995 -1.0544797\n",
      " -0.06809562  0.3563858  -0.2758629   0.6006752   0.42560267  1.8174744\n",
      "  0.03067562 -1.6244637  -1.4849991   0.734509   -1.5620458  -1.8864847\n",
      "  1.9968443   2.013326   -1.1542484   0.29411983  0.78303355 -0.21175358\n",
      " -0.3420053   1.2431169   1.368389    0.23974207 -0.03175199 -0.32571808\n",
      " -2.2968478   1.5980479   0.8403451  -1.7094622   1.8595635  -1.1525131\n",
      " -0.94547427  0.46918732 -0.0401315   0.5516247  -1.3324578   1.2520307\n",
      "  0.3733315   1.1486278   0.24923415 -1.8806117  -2.0052564  -0.5404483\n",
      "  2.9519496   1.9309965 ]\n"
     ]
    }
   ],
   "source": [
    "print(query_embs[0],query_embs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95d48cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.690467 -0.0011640474 6.3633947 1.3787516\n",
      "-7.29783 -0.007016901 7.0519843 1.3921114\n"
     ]
    }
   ],
   "source": [
    "#query_embs_dp=query_embs\n",
    "query_embs_dp.shape\n",
    "query_embs[0]\n",
    "print(np.min(query_embs),np.mean(query_embs),np.max(query_embs),np.std(query_embs))\n",
    "print(np.min(gallery_embs),np.mean(gallery_embs),np.max(gallery_embs),np.std(gallery_embs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7288d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embs_dp[0,1]=np.random.normal(0,2.312213)\n",
    "query_embs_dp=np.exp(0.5) * query_embs_dp +0.01\n",
    "gallery_embs_dp[0,1]=np.random.normal(0,2.3505316)\n",
    "gallery_embs_dp=np.exp(0.5) * gallery_embs_dp +0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe3c43a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3578779 14.685372\n"
     ]
    }
   ],
   "source": [
    "def l1(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.max(np.subtract(actual,pred)).mean()\n",
    "\n",
    "def mse(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.max(np.square(np.subtract(actual,pred)).mean())\n",
    "\n",
    "D0 = query_embs + np.random.normal(0,1.3787516)\n",
    "D1 = query_embs_dp + np.random.normal(0,1.3787516)\n",
    "\n",
    "D2 = gallery_embs + np.random.normal(0,1.3921114)\n",
    "D3 = gallery_embs_dp + np.random.normal(0,1.3921114)\n",
    "#print(D0,D1)\n",
    "#sens1 = l1(query_embs,query_embs_dp)\n",
    "sensq = mse(D0,D1)\n",
    "sensg = mse(D2,D3)\n",
    "print(sensq,sensg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e8f38c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values ['0001' '0001' '0001' ... '1501' '1501' '1501']\n",
      "encoded [  0   0   0 ... 749 749 749]\n",
      "(3368, 750)\n"
     ]
    }
   ],
   "source": [
    "query_data = query_pids\n",
    "query_values = array(query_data)\n",
    "print('values', query_values)\n",
    "# integer encode\n",
    "query_label_encoder = LabelEncoder()\n",
    "query_integer_encoded = query_label_encoder.fit_transform(query_values)\n",
    "print('encoded', query_integer_encoded)\n",
    "# binary encode\n",
    "query_onehot_encoder = OneHotEncoder(sparse=False)\n",
    "query_integer_encoded = query_integer_encoded.reshape(len(query_integer_encoded), 1)\n",
    "query_onehot_encoded = query_onehot_encoder.fit_transform(query_integer_encoded)\n",
    "print(query_onehot_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5e8f744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values ['0001' '0001' '0001' ... '1501' '1501' '1501']\n",
      "encoded [  0   0   0 ... 749 749 749]\n",
      "(13114, 750)\n"
     ]
    }
   ],
   "source": [
    "data = gallery_pids\n",
    "values = array(data)\n",
    "print('values', values)\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print('encoded', integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5569cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train  = D3\n",
    "Y_train_label = onehot_encoded\n",
    "X_test = D0\n",
    "Y_test_label = query_onehot_encoded\n",
    "#print(X_train.size)\n",
    "#print(X_test.size)\n",
    "#print(Y_train_label)\n",
    "#print(Y_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27ad0251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Y_train_label[2:5000])\n",
    "#y_train_label = to_categorical(Y_train_label)\n",
    "#y_train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6c5e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 750)               96750     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96,750\n",
      "Trainable params: 96,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "#model.add( Dense(units=512, input_dim=128, kernel_initializer='normal', activation='relu') )\n",
    "#model.add( Dropout(0.5))\n",
    "model.add( Dense(units=750, input_dim=128, kernel_initializer='normal', activation='softmax') )\n",
    "print( model.summary() )\n",
    "model.compile( loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fe9922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 - 10s - loss: 4.7693 - accuracy: 0.2103 - val_loss: 11.6540 - val_accuracy: 0.0000e+00 - 10s/epoch - 126ms/step\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x=X_train, y=Y_train_label, validation_split=0.2, epochs=1, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89cc86fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "106/106 [==============================] - 2s 21ms/step - loss: 4.9341 - accuracy: 0.2233\n",
      "test loss, test acc: [4.934057712554932, 0.22327791154384613]\n",
      "Generate predictions for 3 samples\n",
      "106/106 [==============================] - 2s 16ms/step\n",
      "predictions shape: [[4.2770654e-02 1.3071230e-03 1.4002275e-04 ... 5.2871305e-04\n",
      "  2.2377255e-03 4.1954595e-04]\n",
      " [7.1114744e-03 2.0610988e-03 1.4104680e-04 ... 3.2420503e-04\n",
      "  9.6199545e-04 7.9970557e-04]\n",
      " [3.5686854e-02 8.7615493e-04 9.3118288e-05 ... 3.7962216e-04\n",
      "  2.3793653e-03 3.4696434e-04]\n",
      " ...\n",
      " [1.0126997e-03 3.6603364e-03 9.2211738e-04 ... 1.4890432e-03\n",
      "  1.8014945e-03 1.5465692e-03]\n",
      " [5.8010884e-04 4.9895034e-03 8.4596995e-04 ... 1.2242500e-03\n",
      "  2.3740786e-03 1.7316269e-03]\n",
      " [5.7673722e-04 2.3656713e-03 8.8875985e-04 ... 1.3285979e-03\n",
      "  2.5859769e-03 1.6622964e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, Y_test_label)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(X_test)\n",
    "print(\"predictions shape:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a71f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffprivlib.models import GaussianNB\n",
    "clf = GaussianNB(epsilon=1,bounds=(-50e50, 50e50))\n",
    "clf.fit(X_train, gallery_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a95318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(X_test)\n",
    "print(\"Test accuracy: %f\" % clf.score(X_test, query_pids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cec2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hbeta(D=np.array([]), beta=1.0):\n",
    "    \"\"\"\n",
    "        Compute the perplexity and the P-row for a specific value of the\n",
    "        precision of a Gaussian distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute P-row and corresponding perplexity\n",
    "    P = np.exp(-D.copy() * beta)\n",
    "    sumP = sum(P)\n",
    "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "    P = P / sumP\n",
    "    return H, P\n",
    "\n",
    "def x2p(X=np.array([]), tol=1e-5, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Performs a binary search to get P-values in such a way that each\n",
    "        conditional Gaussian has the same perplexity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize some variables\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    (n, d) = X.shape\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    P = np.zeros((n, n))\n",
    "    beta = np.ones((n, 1))\n",
    "    logU = np.log(perplexity)\n",
    "\n",
    "    # Loop over all datapoints\n",
    "    for i in range(n):\n",
    "\n",
    "        # Print progress\n",
    "        if i % 500 == 0:\n",
    "            print(\"Computing P-values for point %d of %d...\" % (i, n))\n",
    "\n",
    "        # Compute the Gaussian kernel and entropy for the current precision\n",
    "        betamin = -np.inf\n",
    "        betamax = np.inf\n",
    "        Di = D[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))]\n",
    "        (H, thisP) = Hbeta(Di, beta[i])\n",
    "\n",
    "        # Evaluate whether the perplexity is within tolerance\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while np.abs(Hdiff) > tol and tries < 50:\n",
    "\n",
    "            # If not, increase or decrease precision\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i].copy()\n",
    "                if betamax == np.inf or betamax == -np.inf:\n",
    "                    beta[i] = beta[i] * 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2.\n",
    "            else:\n",
    "                betamax = beta[i].copy()\n",
    "                if betamin == np.inf or betamin == -np.inf:\n",
    "                    beta[i] = beta[i] / 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2.\n",
    "\n",
    "            # Recompute the values\n",
    "            (H, thisP) = Hbeta(Di, beta[i])\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "\n",
    "        # Set the final row of P\n",
    "        P[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))] = thisP\n",
    "\n",
    "    # Return final P-matrix\n",
    "    print(\"Mean value of sigma: %f\" % np.mean(np.sqrt(1 / beta)))\n",
    "    return P\n",
    "\n",
    "def pca(X=np.array([]), no_dims=50):\n",
    "    \"\"\"\n",
    "        Runs PCA on the NxD array X in order to reduce its dimensionality to\n",
    "        no_dims dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Preprocessing the data using PCA...\")\n",
    "    (n, d) = X.shape\n",
    "    X = X - np.tile(np.mean(X, 0), (n, 1))\n",
    "    (l, M) = np.linalg.eig(np.dot(X.T, X))\n",
    "    Y = np.dot(X, M[:, 0:no_dims])\n",
    "    return Y\n",
    "def tsne(X=np.array([]), no_dims=2, initial_dims=50, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    # Initialize variables\n",
    "    X = pca(X, initial_dims).real\n",
    "    (n, d) = X.shape\n",
    "    max_iter = 10\n",
    "    initial_momentum = 0.5\n",
    "    final_momentum = 0.8\n",
    "    eta = 200\n",
    "    min_gain = 0.01\n",
    "    Y = np.random.randn(n, no_dims)\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Compute P-values\n",
    "    P = x2p(X, 1e-5, perplexity)\n",
    "    P = P + np.transpose(P)\n",
    "    P = P / np.sum(P)\n",
    "    P = P * 4.\t\t\t\t\t\t\t\t\t# early exaggeration\n",
    "    P = np.maximum(P, 1e-12)\n",
    "    \n",
    "\n",
    "    # Run iterations\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        # Compute pairwise affinities\n",
    "        sum_Y = np.sum(np.square(Y), 1)\n",
    "        num = -2. * np.dot(Y, Y.T)\n",
    "        num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "        num[range(n), range(n)] = 0.\n",
    "        Q = num / np.sum(num)\n",
    "        Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "        # Compute gradient\n",
    "        PQ = P - Q\n",
    "        for i in range(n):\n",
    "            dY[i, :] = np.sum(np.tile(PQ[:, i] * num[:, i], (no_dims, 1)).T * (Y[i, :] - Y), 0)\n",
    "\n",
    "        # Perform the update\n",
    "        if iter < 20:\n",
    "            momentum = initial_momentum\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)) + \\\n",
    "                (gains * 0.8) * ((dY > 0.) == (iY > 0.))\n",
    "        gains[gains < min_gain] = min_gain\n",
    "        iY = momentum * iY - eta * (gains * dY)\n",
    "        Y = Y + iY\n",
    "        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
    "\n",
    "        # Compute current value of cost function\n",
    "        if (iter + 1) % 10 == 0:\n",
    "            C = np.sum(P * np.log(P / Q))\n",
    "            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n",
    "\n",
    "        # Stop lying about P-values\n",
    "        if iter == 100:\n",
    "            P = P / 4.\n",
    "\n",
    "    # Return solution\n",
    "    return Y\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb470a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "X = gallery_embs[500:700]\n",
    "lbl=list(map(int,gallery_pids))\n",
    "labels = lbl[500:700]#query_pids[0:20]\n",
    "pylab.figure()\n",
    "Y = tsne(X, 2, 50, 20.0)\n",
    "plt=pylab.scatter(Y[:, 0],Y[:,1],10,labels,marker='o')\n",
    "pylab.axis('off')\n",
    "pylab.savefig('rsltn3n1.pdf')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, Y_test_label)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(X_test)\n",
    "print(\"predictions shape:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed85944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "X = query_embs[500:700]\n",
    "lbl=list(map(int,query_pids))\n",
    "labels = lbl[500:700]#query_pids[0:20]\n",
    "pylab.figure()\n",
    "Y = tsne(X, 2, 50, 20.0)\n",
    "plt=pylab.scatter(Y[:, 0],Y[:,1],10,labels,marker='o')\n",
    "pylab.axis('off')\n",
    "pylab.savefig('rsltn3n2.pdf')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a7203",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #file = query_embs\n",
    "    #filel = query_pids\n",
    "    X = query_embs[0:50]\n",
    "    lbl=list(map(int,query_pids))\n",
    "    labels = lbl[0:50]#query_pids[0:20]\n",
    "    print(query_embs,query_pids)\n",
    "    #X = np.loadtxt(\"mnist2500_X.txt\")\n",
    "    pylab.figure()\n",
    "    Y = tsne(X, 2, 50, 20.0)\n",
    "    plt=pylab.scatter(Y[:, 0],Y[:,1],30,labels,marker='+')\n",
    "    pylab.axis('off')\n",
    "    pylab.legend('on')\n",
    "    pylab.savefig('rsltn3n1.pdf')\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #file = query_embs\n",
    "    #filel = query_pids\n",
    "    X = query_embs[0:50]\n",
    "    lbl=list(map(int,query_pids))\n",
    "    labels = lbl[0:50]#query_pids[0:20]\n",
    "    print(query_embs,query_pids)\n",
    "    #X = np.loadtxt(\"mnist2500_X.txt\")\n",
    "    pylab.figure()\n",
    "    Y = tsne(X, 2, 50, 20.0)\n",
    "    plt=pylab.scatter(Y[:, 0],Y[:,1],30,labels,marker='+')\n",
    "    pylab.axis('off')\n",
    "    pylab.legend('on')\n",
    "    pylab.savefig('rsltn3n1.pdf')\n",
    "    pylab.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
