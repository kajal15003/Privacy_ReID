{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5wxzDrx2VxFa",
    "outputId": "9be5ff13-22d0-4b5d-9dbd-4329e93bf541"
   },
   "outputs": [],
   "source": [
    "#!unzip \"/content/Market-1501-v15.09.15.zip\" -d \"/content/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cgte6ISQyfFU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PAPAH_dp59a_"
   },
   "outputs": [],
   "source": [
    "## for Model definition/training\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, concatenate,  Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import InputLayer, Input, Conv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, Activation, MaxPool2D, ZeroPadding2D, SeparableConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "## required for semi-hard triplet loss:\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.framework import dtypes\n",
    "import tensorflow as tf\n",
    "\n",
    "## for visualizing \n",
    "import matplotlib.pyplot as plt, numpy as np\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKhPZW-YyVFx"
   },
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "doWOV86CzgyS"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for filename in os.listdir('/home/k/kajal/triplet-reid/image_root/Market-1501-v15.09.15/bounding_box_train'):\n",
    "    if filename[:4]=='Thum':\n",
    "        continue\n",
    "    labels.append(int(filename[:4]))\n",
    "labels = sorted(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "sXVVIGjxDVh8",
    "outputId": "aab56eb0-f9a6-46d2-eab8-fc437ea32785"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('/home/k/kajal/triplet-reid/image_root/Market-1501-v15.09.15/bounding_box_train/0056_c5s1_007501_02.jpg')\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian(filepathname):\n",
    "    v = cv2.imread(filepathname)\n",
    "    s = cv2.cvtColor(v, cv2.COLOR_BGR2GRAY)\n",
    "    s = cv2.Laplacian(s, cv2.CV_16S, ksize=3)\n",
    "    s = cv2.convertScaleAbs(s)\n",
    "    cv2.imshow('nier',s)\n",
    "    return s\n",
    "laplacian('/home/k/kajal/triplet-reid/image_root/Market-1501-v15.09.15/bounding_box_train/0056_c5s1_007501_02.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H19diTPUV-K5"
   },
   "outputs": [],
   "source": [
    "img_data = []\n",
    "for filename in os.listdir('/home/k/kajal/triplet-reid/image_root/Market-1501-v15.09.15/bounding_box_train'):\n",
    "    if filename[:4]=='Thum':\n",
    "        continue\n",
    "    else:\n",
    "        img = cv2.imread('/home/k/kajal/triplet-reid/image_root/Market-1501-v15.09.15/bounding_box_train'+'/'+filename)\n",
    "        # Lets apply medain blur to our images\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.medianBlur(gray, 3)\n",
    "        # Then we apply adpativeThresholding to get the better img\n",
    "        edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, 3, 3)\n",
    "        # Then we use morphism\n",
    "        gray = cv2.morphologyEx(gray,cv2.MORPH_OPEN,(4,4))\n",
    "        img_data.append(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50hpaCK6bOET",
    "outputId": "7967b859-60c0-4e41-ed4f-be6577c70c24"
   },
   "outputs": [],
   "source": [
    "img_data = np.array(img_data)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-FwzsVs7BZb"
   },
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4CtMidBvXiO"
   },
   "source": [
    "#### Pairwise_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0BJdqcW7C0j"
   },
   "outputs": [],
   "source": [
    "def pairwise_distance(feature, squared=False):\n",
    "    pairwise_distances_squared = math_ops.add(\n",
    "        math_ops.reduce_sum(math_ops.square(feature), axis=[1], keepdims=True),\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.square(array_ops.transpose(feature)),\n",
    "            axis=[0],\n",
    "            keepdims=True)) - 2.0 * math_ops.matmul(feature,\n",
    "                                                    array_ops.transpose(feature))\n",
    "\n",
    "    # Deal with numerical inaccuracies. Set small negatives to zero.\n",
    "    pairwise_distances_squared = math_ops.maximum(pairwise_distances_squared, 0.0)\n",
    "    # Get the mask where the zero distances are at.\n",
    "    error_mask = math_ops.less_equal(pairwise_distances_squared, 0.0)\n",
    "\n",
    "    # Optionally take the sqrt.\n",
    "    if squared:\n",
    "        pairwise_distances = pairwise_distances_squared\n",
    "    else:\n",
    "        pairwise_distances = math_ops.sqrt(\n",
    "            pairwise_distances_squared + math_ops.to_float(error_mask) * 1e-16)\n",
    "\n",
    "    # Undo conditionally adding 1e-16.\n",
    "    pairwise_distances = math_ops.multiply(\n",
    "        pairwise_distances, math_ops.to_float(math_ops.logical_not(error_mask)))\n",
    "\n",
    "    num_data = array_ops.shape(feature)[0]\n",
    "    # Explicitly set diagonals to zero.\n",
    "    mask_offdiagonals = array_ops.ones_like(pairwise_distances) - array_ops.diag(\n",
    "        array_ops.ones([num_data]))\n",
    "    pairwise_distances = math_ops.multiply(pairwise_distances, mask_offdiagonals)\n",
    "    return pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbM8q8UobdXo"
   },
   "outputs": [],
   "source": [
    "def masked_minimum(data, mask, dim=1):\n",
    "    axis_maximums = math_ops.reduce_max(data, dim, keepdims=True)\n",
    "    masked_minimums = math_ops.reduce_min(\n",
    "        math_ops.multiply(data - axis_maximums, mask), dim,\n",
    "        keepdims=True) + axis_maximums\n",
    "    return masked_minimums\n",
    "\n",
    "def masked_maximum(data, mask, dim=1):\n",
    "    axis_minimums = math_ops.reduce_min(data, dim, keepdims=True)\n",
    "    masked_maximums = math_ops.reduce_max(\n",
    "        math_ops.multiply(data - axis_minimums, mask), dim,\n",
    "        keepdims=True) + axis_minimums\n",
    "    return masked_maximums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sJWux_HvcVd"
   },
   "source": [
    "#### Triplet Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IDgusPX7DYC"
   },
   "outputs": [],
   "source": [
    "def triplet_loss_adapted_from_tf(y_true, y_pred):\n",
    "    del y_true\n",
    "    margin = 1.\n",
    "    labels = y_pred[:, :1]\n",
    "\n",
    " \n",
    "    labels = tf.cast(labels, dtype='int32')\n",
    "\n",
    "    embeddings = y_pred[:, 1:]\n",
    "    # Build pairwise squared distance matrix.\n",
    "    pdist_matrix = pairwise_distance(embeddings, squared=True)\n",
    "    # Build pairwise binary adjacency matrix.\n",
    "    adjacency = math_ops.equal(labels, array_ops.transpose(labels))\n",
    "    # Invert so we can select negatives only.\n",
    "    adjacency_not = math_ops.logical_not(adjacency)\n",
    "\n",
    "    # global batch_size  \n",
    "    batch_size = array_ops.size(labels) # was 'array_ops.size(labels)'\n",
    "\n",
    "    # Compute the mask.\n",
    "    pdist_matrix_tile = array_ops.tile(pdist_matrix, [batch_size, 1])\n",
    "    mask = math_ops.logical_and(\n",
    "        array_ops.tile(adjacency_not, [batch_size, 1]),\n",
    "        math_ops.greater(\n",
    "            pdist_matrix_tile, array_ops.reshape(\n",
    "                array_ops.transpose(pdist_matrix), [-1, 1])))\n",
    "    mask_final = array_ops.reshape(\n",
    "        math_ops.greater(\n",
    "            math_ops.reduce_sum(\n",
    "                math_ops.cast(mask, dtype=dtypes.float32), 1, keepdims=True),\n",
    "            0.0), [batch_size, batch_size])\n",
    "    mask_final = array_ops.transpose(mask_final)\n",
    "\n",
    "    adjacency_not = math_ops.cast(adjacency_not, dtype=dtypes.float32)\n",
    "    mask = math_ops.cast(mask, dtype=dtypes.float32)\n",
    "\n",
    "    # negatives_outside: smallest D_an where D_an > D_ap.\n",
    "    negatives_outside = array_ops.reshape(\n",
    "        masked_minimum(pdist_matrix_tile, mask), [batch_size, batch_size])\n",
    "    negatives_outside = array_ops.transpose(negatives_outside)\n",
    "\n",
    "    # negatives_inside: largest D_an.\n",
    "    negatives_inside = array_ops.tile(\n",
    "        masked_maximum(pdist_matrix, adjacency_not), [1, batch_size])\n",
    "    semi_hard_negatives = array_ops.where(\n",
    "        mask_final, negatives_outside, negatives_inside)\n",
    "\n",
    "    loss_mat = math_ops.add(margin, pdist_matrix - semi_hard_negatives)\n",
    "\n",
    "    mask_positives = math_ops.cast(\n",
    "        adjacency, dtype=dtypes.float32) - array_ops.diag(\n",
    "        array_ops.ones([batch_size]))\n",
    "\n",
    "    # In lifted-struct, the authors multiply 0.5 for upper triangular\n",
    "    #   in semihard, they take all positive pairs except the diagonal.\n",
    "    num_positives = math_ops.reduce_sum(mask_positives)\n",
    "\n",
    "    semi_hard_triplet_loss_distance = math_ops.truediv(\n",
    "        math_ops.reduce_sum(\n",
    "            math_ops.maximum(\n",
    "                math_ops.multiply(loss_mat, mask_positives), 0.0)),\n",
    "        num_positives,\n",
    "        name='triplet_semihard_loss')\n",
    "    \n",
    "    ### Code from Tensorflow function semi-hard triplet loss ENDS here.\n",
    "    return semi_hard_triplet_loss_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVtPhTww7IZS"
   },
   "outputs": [],
   "source": [
    "def create_base_network(image_input_shape, embedding_size):\n",
    "    input_image = Input(shape=image_input_shape)\n",
    "    x =  Conv2D(256, kernel_size = 3,activation = 'relu')(input_image)\n",
    "    x =  Conv2D(128, kernel_size = 3, activation = 'relu')(input_image)\n",
    "    # x = AveragePooling2D(pool_size = (3,3), strides = 3)(x)\n",
    "    x =  Conv2D(64, kernel_size = 3, activation = 'relu')(input_image)\n",
    "    x = Flatten()(input_image)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(embedding_size)(x)\n",
    "\n",
    "    base_network = Model(inputs=input_image, outputs=x)\n",
    "    plot_model(base_network, to_file='base_network.png', show_shapes=True, show_layer_names=True)\n",
    "    return base_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYgWyTdb7aOz"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # in case this scriot is called from another file, let's make sure it doesn't start training the network...\n",
    "    batch_size = 256\n",
    "    epochs = 25\n",
    "    train_flag = True  # either     True or False\n",
    "    embedding_size = 64\n",
    "    no_of_components = 2  # for visualization -> PCA.fit_transform()\n",
    "    step = 10\n",
    "    # The data, split between train and test sets\n",
    "    (x_train, y_train) = img_data,np.array(labels)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_train /= 255.\n",
    "    input_image_shape = (128, 64, 1)\n",
    "    x_val = x_train[:2000, :, :]\n",
    "    y_val = y_train[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ebzxc2437piU",
    "outputId": "b9be5a2f-e8db-4d4a-9f25-a306c6382316"
   },
   "outputs": [],
   "source": [
    "  # Network training...\n",
    "if train_flag == True:\n",
    "        base_network = create_base_network(input_image_shape, embedding_size)\n",
    "\n",
    "        input_images = Input(shape=input_image_shape, name='input_image') # input layer for images\n",
    "        input_labels = Input(shape=(1,), name='input_label')    # input layer for labels\n",
    "        embeddings = base_network([input_images])               # output of network -> embeddings\n",
    "        labels_plus_embeddings = concatenate([input_labels, embeddings])  # concatenating the labels + embeddings\n",
    "\n",
    "        # Defining a model with inputs (images, labels) and outputs (labels_plus_embeddings)\n",
    "        model = Model(inputs=[input_images, input_labels],\n",
    "                      outputs=labels_plus_embeddings)\n",
    "\n",
    "        model.summary()\n",
    "        plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "        # train session\n",
    "        opt = Adam(lr=0.01)  # choose optimiser. RMS is good too!\n",
    "\n",
    "        model.compile(loss=triplet_loss_adapted_from_tf,\n",
    "                      optimizer=opt)\n",
    "\n",
    "        # Uses 'dummy' embeddings + dummy gt labels. Will be removed as soon as loaded, to free memory\n",
    "        dummy_gt_train = np.zeros((len(x_train), embedding_size + 1))\n",
    "        dummy_gt_val = np.zeros((len(x_val), embedding_size + 1))\n",
    "\n",
    "        x_train = np.reshape(x_train, (len(x_train), x_train.shape[1], x_train.shape[2], 1))\n",
    "        x_val = np.reshape(x_val, (len(x_val), x_train.shape[1], x_train.shape[2], 1))\n",
    "\n",
    "        H = model.fit(\n",
    "            x=[x_train,y_train],\n",
    "            y=dummy_gt_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data = ([x_val,y_val],dummy_gt_val))\n",
    "        \n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.plot(H.history['loss'], label='training loss')\n",
    "        plt.plot(H.history['val_loss'], label='validation loss')\n",
    "        plt.legend()\n",
    "        plt.title('Train/validation loss')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0bf8aHVvQw2"
   },
   "source": [
    "#### Testing our Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zS8l_WWzfv2L"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('/home/k/kajal/triplet-reid/image_root/Market-1501-v15.09.15/bounding_box_test/-1_c1s1_015751_04.jpg')# Lets apply medain blur to our images\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.medianBlur(gray, 3)\n",
    "# Then we apply adpativeThresholding to get the better img\n",
    "edges = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY, 3, 3)\n",
    "# Then we use morphism\n",
    "gray = cv2.morphologyEx(gray,cv2.MORPH_OPEN,(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTapftah0gYB",
    "outputId": "a4c4c342-9497-4486-b5f8-6469b1c17fa1"
   },
   "outputs": [],
   "source": [
    "len(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGn8GkttzsHA"
   },
   "outputs": [],
   "source": [
    "# Test the network\n",
    "\n",
    "# creating an empty network\n",
    "testing_embeddings = create_base_network(input_image_shape,\n",
    "                                          embedding_size=embedding_size)\n",
    "x_embeddings_before_train = testing_embeddings.predict(np.reshape(x_val, (len(x_val), 128, 64, 1)))\n",
    "# Grabbing the weights from the trained network\n",
    "for layer_target, layer_source in zip(testing_embeddings.layers, model.layers[2].layers):\n",
    "    weights = layer_source.get_weights()\n",
    "    layer_target.set_weights(weights)\n",
    "    del weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujyYBnWY2Aie"
   },
   "source": [
    "#### Lets see how well our model learned by doing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d35M-7j9z8mc",
    "outputId": "df15575d-5849-4023-f99d-bfd85903313c"
   },
   "outputs": [],
   "source": [
    "# Visualizing the effect of embeddings -> using PCA!\n",
    "\n",
    "x_embeddings = testing_embeddings.predict(np.reshape(x_val, (len(x_val), 128, 64, 1)))\n",
    "dict_embeddings = {}\n",
    "dict_gray = {}\n",
    "test_class_labels = np.unique(np.array(y_val))\n",
    "\n",
    "pca = PCA(n_components=no_of_components)\n",
    "decomposed_embeddings = pca.fit_transform(x_embeddings)\n",
    "#     x_test_reshaped = np.reshape(x_test, (len(x_test), 28 * 28))\n",
    "decomposed_gray = pca.fit_transform(x_embeddings_before_train)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "for label in test_class_labels:\n",
    "    decomposed_embeddings_class = decomposed_embeddings[y_val == label]\n",
    "    decomposed_gray_class = decomposed_gray[y_val == label]\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.scatter(decomposed_gray_class[::step,1], decomposed_gray_class[::step,0],label=str(label))\n",
    "    plt.title('before training (embeddings)')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(decomposed_embeddings_class[::step, 1], decomposed_embeddings_class[::step, 0], label=str(label))\n",
    "    plt.title('after @%d epochs' % epochs)\n",
    "    plt.legend()\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGTAr_R81tTA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
